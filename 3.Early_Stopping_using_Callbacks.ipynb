{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "Fashion_MNIST data and description is available on github: https://github.com/zalandoresearch/fashion-mnist <br>\n",
    "\n",
    "It consists of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes as given below:\n",
    "\n",
    "**Label \tDescription** <br>\n",
    "0 \tT-shirt/top <br>\n",
    "1 \tTrouser <br>\n",
    "2 \tPullover <br>\n",
    "3 \tDress <br>\n",
    "4 \tCoat <br>\n",
    "5 \tSandal <br>\n",
    "6 \tShirt <br>\n",
    "7 \tSneaker <br>\n",
    "8 \tBag <br>\n",
    "9 \tAnkle boot <br>\n",
    "\n",
    "**Points to be Noted**\n",
    "1. Each image is of size 28x28 = 784 pixels.\n",
    "2. Grayscale images have a total of 255 shades/pixels ranges from 0 to 255 to define how much dark or light that pixel will be. 0 = Maximum Dark; 255 = Maximum White.\n",
    "3. Each row is a separate image and column as labels (0-9)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks\n",
    "Used for earty stopping of model. for eg. stopping on a apecific onsition like when Loss printed in the logs is less than a specif value or early stopping when model is not able to reduce the loss further "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-rc0\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 2us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 7s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 4s 1us/step\n",
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 22s 360us/sample - loss: 0.4711\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 20s 337us/sample - loss: 0.3606\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 21s 344us/sample - loss: 0.3231\n",
      "Epoch 4/10\n",
      "59872/60000 [============================>.] - ETA: 0s - loss: 0.2973\n",
      "Reached 70% accuracy so cancelling training!\n",
      "60000/60000 [==============================] - 21s 343us/sample - loss: 0.2975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe460d4a4d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install -U tensorflow==2.0.0-beta1  # to install tensorflow 2.0-beta1 in Kaggle notebook\n",
    "# Compile and run with TensorFlow 2.0 \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "# create a callback class\n",
    "class myCallback(tf.keras.callbacks.Callback):  \n",
    "    def on_epoch_end(self, epoch, logs=None):  # on_epoch_end is a standard function defined in tensorflow doc & called at the end of epoch  \n",
    "        if(logs.get('loss')<0.3):   # get the 'loss' output from printed logs\n",
    "          print(\"\\nReached 70% accuracy so cancelling training!\")\n",
    "          self.model.stop_training = True    # standard flag used to stop the model when abov condition meets\n",
    "\n",
    "On_epoch_end_callback = myCallback()     # Instantiate the class\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "# Download Fashion mnist data from server\n",
    "(x_training_images, y_training_labels), (x_test_images, y_test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the input images to range between 0 to 1\n",
    "x_training_images = x_training_images/255.0\n",
    "x_test_images = x_test_images/255.0\n",
    "\n",
    "#Define the model by adding layers\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "#Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "# Train the model\n",
    "model.fit(x_training_images, y_training_labels, epochs=10, callbacks=[On_epoch_end_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Example of callback: Model will stop training when Loss stops reducing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta1\n",
      "Train on 60000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 0.4776\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.3603\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.3214\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.2969\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.2821\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.2667\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.2531\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.2404\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 0.2323\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.2215\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.2130\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.2067\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.1967\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1919\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.1852\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.1805\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.1739\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1683\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.1622\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.1588\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.1529\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1490\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.1452\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.1435\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1365\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.1338\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.1315\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.1296\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.1263\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1203\n",
      "Epoch 31/100\n",
      "59584/60000 [============================>.] - ETA: 0s - loss: 0.1207Restoring model weights from the end of the best epoch.\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1207\n",
      "Epoch 00031: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fecfc76e8d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code compile and run with Tsnorflow 2.0\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "# Callback Class\n",
    "class EarlyStoppingAtMinLoss(tf.keras.callbacks.Callback):\n",
    "  \"\"\"Stop training when the loss is at its min, i.e. the loss stops decreasing.\n",
    "  Arguments:\n",
    "      patience: Number of epochs to wait after min has been hit. After this\n",
    "      number of no improvement, training stops.\n",
    "  \"\"\"\n",
    "# This method is called when class in Instantiated\n",
    "  def __init__(self, patience=0):\n",
    "    super(EarlyStoppingAtMinLoss, self).__init__()\n",
    "\n",
    "    self.patience = patience\n",
    "\n",
    "    # best_weights to store the weights at which the minimum loss occurs.\n",
    "    self.best_weights = None\n",
    "\n",
    "# This method is called at the begining of training  \n",
    "  def on_train_begin(self, logs=None):\n",
    "    # The number of epoch it has waited when loss is no longer minimum.\n",
    "    self.wait = 0\n",
    "    # The epoch the training stops at.\n",
    "    self.stopped_epoch = 0\n",
    "    # Initialize the best as infinity.\n",
    "    self.best = np.Inf\n",
    "\n",
    "# This method is called on every end of EPOCH     \n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    current = logs.get('loss')\n",
    "    if(current < self.best):\n",
    "      self.best = current\n",
    "      self.wait = 0\n",
    "      # Record the best weights if current results is better (less).\n",
    "      self.best_weights = self.model.get_weights()\n",
    "    else:\n",
    "      self.wait += 1\n",
    "      if self.wait >= self.patience:\n",
    "        self.stopped_epoch = epoch\n",
    "        self.model.stop_training = True   # early stopping of model\n",
    "        print('Restoring model weights from the end of the best epoch.')\n",
    "        self.model.set_weights(self.best_weights)\n",
    "\n",
    "# This method is called when training is finished either of its own or by early stopping        \n",
    "  def on_train_end(self, logs=None):\n",
    "    if self.stopped_epoch > 0:\n",
    "      print('Epoch %05d: early stopping' % (self.stopped_epoch + 1))\n",
    "\n",
    "Early_stop_callback = EarlyStoppingAtMinLoss()     # Instantiate the class\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "# Downloaing Fashion Mnist data\n",
    "(x_training_images, y_training_labels), (x_test_images, y_test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the data in the range 0 to 1\n",
    "x_training_images = x_training_images/255.0\n",
    "x_test_images = x_test_images/255.0\n",
    "#Define the model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.fit(x_training_images, y_training_labels, epochs=100, callbacks=[Early_stop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
