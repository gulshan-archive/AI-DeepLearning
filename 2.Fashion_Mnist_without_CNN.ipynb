{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Description\nFashion_MNIST data and description is available on github: https://github.com/zalandoresearch/fashion-mnist <br>\n\nIt consists of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes as given below:\n\n**Label \tDescription** <br>\n0 \tT-shirt/top <br>\n1 \tTrouser <br>\n2 \tPullover <br>\n3 \tDress <br>\n4 \tCoat <br>\n5 \tSandal <br>\n6 \tShirt <br>\n7 \tSneaker <br>\n8 \tBag <br>\n9 \tAnkle boot <br>\n\n**Points to be Noted**\n1. Each image is of size 28x28 = 784 pixels.\n2. Grayscale images have a total of 255 shades/pixels ranges from 0 to 255 to define how much dark or light that pixel will be. 0 = Maximum Dark; 255 = Maximum White.\n3. Each row is a separate image and column as labels (0-9)."},{"metadata":{},"cell_type":"markdown","source":"## Import Modules"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# !pip install -U tensorflow==2.0.0-beta1  # to install tensorflow 2.0-beta1 in Kaggle notebook\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nprint(tf.__version__)   # prints tensorflow installed version\nfrom tensorflow import keras","execution_count":37,"outputs":[{"output_type":"stream","text":"2.0.0-beta1\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Download Fashion MNIST Data\nSince this data is already added in tensorflow and an api is created. So, we can directly use that api to directly downlaod the data from server."},{"metadata":{"trusted":true},"cell_type":"code","source":"mnist = tf.keras.datasets.fashion_mnist\n(x_training_images, y_training_labels), (x_testing_images, y_testing_labels) = mnist.load_data()","execution_count":38,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prints some of the Loaded Dataset\nNotice all the values of pixels ranges from 0-255 because of grayscale images"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nprint(y_training_labels[59990])  # Display the training label for the image number passed ranges from 0-59999\nprint(x_training_images[59990])      # Display the training image data correponding to number passed\nplt.imshow(x_training_images[59990]) # Display the image correponding to index passed\n#plt.imshow(x_training_images[59990], cmap='gray')  # Display image in grayscale","execution_count":39,"outputs":[{"output_type":"stream","text":"4\n[[  0   0   0   0   0   0   0   0   1   0   0 127 138 102 109 134 126  92\n    0   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   2   0  24 154 187 239 188 255 154 148\n    0   0   1   0   1   0   0   0   0   0]\n [  0   0   0   0   0   0   0   0   9   0  92 151 170 158  70 194 124 150\n   11   0   5   0   1   0   0   0   0   0]\n [  0   0   0   0   0   0   1   0   0   0 160 191 202 147  93 177 137 143\n   85   0   0   0   0   0   0   0   0   0]\n [  0   0   0   0   0   1   0   0  48 109 181 192 187 141 102 212 151 117\n  150  96  17   0   0   0   0   0   0   0]\n [  0   0   0   0   0   0   0 113 138 124 145 147 170 109 116 141 143 107\n  128 124 130  66   0   1   0   0   0   0]\n [  0   0   0   0   0   0  39 148 119 119 109 103 121 106 110 106 137 102\n  110 114 119 126   0   0   0   0   0   0]\n [  0   0   0   0   0   0  70 162 123 114 102 177 147  97 117 102 141 107\n  100 110 123 141  38   0   0   0   0   0]\n [  0   0   0   0   0   0 127 151 145 117 111 123 120 106 116  99 121 121\n  102  94 133 137  73   0   0   0   0   0]\n [  0   0   0   0   0   0 158 128 164 145 117 100 104 106 109 104 113 127\n   87 134 134 126 106   0   0   0   0   0]\n [  0   0   0   0   0   0 147 124 170 164 120 117 111 109 107 104 110 121\n   87 162 148 123 126   0   0   0   0   0]\n [  0   0   0   0   0   7 158 123 181 189 126 127 114 114 117 110 110 119\n  109 154 164 121 137   0   0   0   0   0]\n [  0   0   0   0   0  24 153 130 167 165 137 131 119 114 114 116 120 126\n  121 154 164 121 144   5   0   0   0   0]\n [  0   0   0   0   0  45 145 133 128 164 143 133 120 117 113 107 121 124\n  128 120 143 137 140  17   0   0   0   0]\n [  0   0   0   0   0  66 140 141  99 157 148 130 121 121 123 117 124 123\n  138 109 130 144 136  34   0   0   0   0]\n [  0   0   0   0   0  79 136 154  80 161 147 131 124 121 117 114 127 124\n  147  80 111 155 136  52   0   0   0   0]\n [  0   0   0   0   0  90 133 161  49 172 144 127 121 123 117 113 130 111\n  140 110  79 161 128  63   0   0   0   0]\n [  0   0   0   0   0  99 128 158  19 250 124 128 120 123 119 114 126 121\n  123 182  76 162 127  68   0   0   0   0]\n [  0   0   0   0   0 107 137 144  45 245 107 136 127 123 120 120 133 120\n  110 168  85 160 130  75   0   0   0   0]\n [  0   0   0   0   0 116 141 117 103 202 117 130 131 127 111 130 138 119\n  116 158  80 175 138  80   0   0   0   0]\n [  0   0   0   0   0 120 151  90 151 189 119 130 126 127 113 145 133 119\n  111 170 123 153 145  83   0   0   0   0]\n [  0   0   0   0   0 116 154  90 174 187 120 134 126 126 123 148 126 120\n  117 133 126 157 147  83   0   0   0   0]\n [  0   0   0   0   0 121 144 104 189 158 123 134 131 124 126 147 123 124\n  123 127 144 154 153  85   0   0   0   0]\n [  0   0   0   0   0 127 140 117 165 144 133 133 130 123 143 148 124 128\n  121 133  94 150 153  90   0   0   0   0]\n [  0   0   0   0   0 121 144 114 154 202 164 124 134 131 153 141 137 128\n  123 145 111 145 147  87   0   0   0   0]\n [  0   0   0   0   0 126 150  94 127 236 162 143 147 141 151 140 143 151\n  136 175  73 136 147  86   0   0   0   0]\n [  0   0   0   0   0 148 157 113   0  52  25  18  22  19  18  29  28  36\n   29  18   0 178 154  99   0   0   0   0]\n [  0   0   0   0   0 117 154  87   0   0   0   0   0   0   0   0   0   0\n    0   0   0 130 148  77   0   0   0   0]]\n","name":"stdout"},{"output_type":"execute_result","execution_count":39,"data":{"text/plain":"<matplotlib.image.AxesImage at 0x7f46636fb8d0>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"## Normalize the Input Dataset\nData required by Neural network ranges from -1 to 1 or 0 to 1. So, we can do it simply by dividing each image pixel with 255"},{"metadata":{"trusted":true},"cell_type":"code","source":"# x_training_images = x_training_images.astype('float32')\n# x_test_images = x_test_images.astype('float32')\nx_training_images  = x_training_images / 255.0  # divide by 255.0 to make output as float32 value\nx_testing_images = x_testing_images / 255.0","execution_count":40,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define the Model\nSequential: That defines a SEQUENCE of layers in the neural network\n\nFlatten: It takes the input 2d image (for eg. 28x28) and converts or flatten it into a 1 dimensional vector (784).\n\nDense: Adds a layer of neurons\n\nEach layer of neurons need an activation function to tell them what to do. \nRelu effectively means \"If X>0 return X, else return 0\" -- so what it does it it only passes values 0 or greater to the next layer in the network.\n\nSoftmax takes a set of values, and effectively picks the biggest one, so, for example, if the output of the last layer looks like [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05], it converts it into [0,0,0,0,1,0,0,0,0] and gives the biggest value\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), # added 1st layer with 128 neurons\n                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)]) # Added 2nd/Output layer with 10 neurons because our output is catagorized into 10 classes","execution_count":41,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Compile & Train the Model\nNotice the Loss and accuracy on completion. Both should be inversely proportional to each other. The EPOCH's can be set to value untill the Loss keeps on going down and accuracy keep son increasing"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer = 'Adam',\n              loss = 'sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n# Train the model\nhistory = model.fit(x_training_images, y_training_labels, epochs=30)","execution_count":42,"outputs":[{"output_type":"stream","text":"Train on 60000 samples\nEpoch 1/30\n60000/60000 [==============================] - 4s 75us/sample - loss: 0.4981 - accuracy: 0.8253\nEpoch 2/30\n60000/60000 [==============================] - 4s 69us/sample - loss: 0.3755 - accuracy: 0.8650\nEpoch 3/30\n60000/60000 [==============================] - 4s 70us/sample - loss: 0.3368 - accuracy: 0.8775\nEpoch 4/30\n60000/60000 [==============================] - 4s 70us/sample - loss: 0.3131 - accuracy: 0.8854\nEpoch 5/30\n60000/60000 [==============================] - 4s 67us/sample - loss: 0.2947 - accuracy: 0.8905\nEpoch 6/30\n60000/60000 [==============================] - 4s 67us/sample - loss: 0.2819 - accuracy: 0.8954\nEpoch 7/30\n60000/60000 [==============================] - 4s 67us/sample - loss: 0.2686 - accuracy: 0.9010\nEpoch 8/30\n60000/60000 [==============================] - 4s 67us/sample - loss: 0.2586 - accuracy: 0.9037\nEpoch 9/30\n60000/60000 [==============================] - 4s 68us/sample - loss: 0.2469 - accuracy: 0.9075\nEpoch 10/30\n60000/60000 [==============================] - 4s 67us/sample - loss: 0.2390 - accuracy: 0.9110\nEpoch 11/30\n60000/60000 [==============================] - 4s 68us/sample - loss: 0.2294 - accuracy: 0.9142\nEpoch 12/30\n60000/60000 [==============================] - 4s 67us/sample - loss: 0.2233 - accuracy: 0.9154\nEpoch 13/30\n60000/60000 [==============================] - 4s 67us/sample - loss: 0.2188 - accuracy: 0.9177\nEpoch 14/30\n60000/60000 [==============================] - 4s 66us/sample - loss: 0.2107 - accuracy: 0.9208\nEpoch 15/30\n60000/60000 [==============================] - 4s 68us/sample - loss: 0.2056 - accuracy: 0.9232\nEpoch 16/30\n60000/60000 [==============================] - 4s 67us/sample - loss: 0.2004 - accuracy: 0.9243\nEpoch 17/30\n60000/60000 [==============================] - 4s 67us/sample - loss: 0.1930 - accuracy: 0.9273\nEpoch 18/30\n60000/60000 [==============================] - 4s 69us/sample - loss: 0.1889 - accuracy: 0.9293\nEpoch 19/30\n60000/60000 [==============================] - 4s 69us/sample - loss: 0.1803 - accuracy: 0.9323\nEpoch 20/30\n60000/60000 [==============================] - 4s 68us/sample - loss: 0.1769 - accuracy: 0.9329\nEpoch 21/30\n60000/60000 [==============================] - 4s 67us/sample - loss: 0.1738 - accuracy: 0.9344\nEpoch 22/30\n60000/60000 [==============================] - 4s 67us/sample - loss: 0.1704 - accuracy: 0.9360\nEpoch 23/30\n60000/60000 [==============================] - 4s 66us/sample - loss: 0.1644 - accuracy: 0.9387\nEpoch 24/30\n60000/60000 [==============================] - 4s 67us/sample - loss: 0.1596 - accuracy: 0.9395\nEpoch 25/30\n60000/60000 [==============================] - 4s 67us/sample - loss: 0.1558 - accuracy: 0.9426\nEpoch 26/30\n60000/60000 [==============================] - 4s 66us/sample - loss: 0.1539 - accuracy: 0.9423\nEpoch 27/30\n60000/60000 [==============================] - 4s 67us/sample - loss: 0.1490 - accuracy: 0.9437\nEpoch 28/30\n60000/60000 [==============================] - 4s 66us/sample - loss: 0.1457 - accuracy: 0.9456\nEpoch 29/30\n60000/60000 [==============================] - 4s 67us/sample - loss: 0.1423 - accuracy: 0.9462\nEpoch 30/30\n60000/60000 [==============================] - 4s 67us/sample - loss: 0.1419 - accuracy: 0.9466\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Test the Model using Test set\nIt returns the loss value & Accuracy for test data. This is the step where the model is given with new unseen images to check how well it has learned.\nNotice that Loss and Accuracy will be somewhat lesser that the training Loss and accuracy but its fine\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_score = model.evaluate(x_testing_images, y_testing_labels)  # Returns the loss value & accuracy of model in test mode. Computation is done in batches.\nprint(test_score)\nprint(f\"Test Loss = {test_score[0]}\")\nprint(f\"Test Accuracy = {test_score[1]}\")","execution_count":43,"outputs":[{"output_type":"stream","text":"10000/10000 [==============================] - 0s 45us/sample - loss: 0.3785 - accuracy: 0.8881\n[0.37845147188305855, 0.8881]\nTest Loss = 0.37845147188305855\nTest Accuracy = 0.8881000280380249\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"It returns the a list of 10 numbes which shows the prediction probability for a given image for classes `0 to 9`. Or it is like how much confident the model is to predict which class the given image belogs to.\n\n"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Returns numpy array of predictions\nclassifications = model.predict(x_testing_images)  # generates output predictions for input samples. COmputation is done in batches\n\nprint(classifications[20])\nprint(y_testing_labels[20])\n#print(y_testing_labels[0])\nplt.imshow(x_testing_images[20]) # Display the image correponding to index passed\n# As you can see from tha table in begining that number 2 is Pullover. So, our model has predicted well ","execution_count":44,"outputs":[{"output_type":"stream","text":"[4.0569901e-03 1.7593360e-04 9.9516124e-01 1.0143161e-09 5.4332608e-04\n 8.0120698e-16 6.2244893e-05 4.9057753e-09 1.9474136e-07 7.3967593e-10]\n2\n","name":"stdout"},{"output_type":"execute_result","execution_count":44,"data":{"text/plain":"<matplotlib.image.AxesImage at 0x7f4671f0aeb8>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"## Callback"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)\n\nclass myCallback(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs={}):\n    if(logs.get('loss')<0.4):\n      print(\"\\nReached 60% accuracy so cancelling training!\")\n      self.model.stop_training = True\n\ncallbacks = myCallback()\nmnist = tf.keras.datasets.fashion_mnist\n(x_training_images, y_training_labels), (x_test_images, y_test_labels) = mnist.load_data()\nx_training_images = x_training_images/255.0\nx_test_images = x_test_images/255.0\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n])\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\nmodel.fit(x_training_images, y_training_labels, epochs=10, callbacks=[callbacks])\n","execution_count":45,"outputs":[{"output_type":"stream","text":"2.0.0-beta1\nTrain on 60000 samples\nEpoch 1/10\n60000/60000 [==============================] - 6s 101us/sample - loss: 0.4729\nEpoch 2/10\n59936/60000 [============================>.] - ETA: 0s - loss: 0.3603\nReached 60% accuracy so cancelling training!\n60000/60000 [==============================] - 6s 93us/sample - loss: 0.3605\n","name":"stdout"},{"output_type":"execute_result","execution_count":45,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f4671eaecc0>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}