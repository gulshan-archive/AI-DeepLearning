{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ways_to_download_And_Extract_zipped_dataset.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gulshan-archive/Artificial-Intelligence-DeepLearning/blob/master/Ways_to_download_And_Extract_zipped_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ze0f544J9wzn",
        "colab_type": "text"
      },
      "source": [
        "## Import TensorFlow version 2.x"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6apvQYclsAU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "46db3841-4020-4635-f7ce-e161ed39e48d"
      },
      "source": [
        "try:\n",
        "  # Use the %tensorflow_version magic if in colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4t30wwPX95A8",
        "colab_type": "text"
      },
      "source": [
        "## Method 1: Downloading dataset from Internet Link "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yn5dEZb1wODS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "297a3647-6a22-40cd-8c35-c9a5fbf6140b"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O /tmp/cats_and_dogs_filtered.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-21 15:33:21--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.203.128, 2404:6800:4008:c05::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.203.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "\r          /tmp/cats   0%[                    ]       0  --.-KB/s               \r         /tmp/cats_  43%[=======>            ]  28.52M   143MB/s               \r        /tmp/cats_a  48%[========>           ]  32.01M  79.0MB/s               \r/tmp/cats_and_dogs_ 100%[===================>]  65.43M   125MB/s    in 0.5s    \n",
            "\n",
            "2019-11-21 15:33:22 (125 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FxlL1cL-MHI",
        "colab_type": "text"
      },
      "source": [
        "## Unzip and list directories and sub directories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMn1rx1RwabC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "d9fd5027-dd4f-4f8b-f7d8-5fa1b2463d26"
      },
      "source": [
        "def walk_through_dir(zip_file_path):\n",
        "  \"\"\"\n",
        "  Function to unzip and print the list of directories and sub directories in the path passed as argument\n",
        "  Parameters:\n",
        "  file_path: local zipped directory path\n",
        "  \"\"\"\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  # file_path = zip_file_path.split('.')[0]\n",
        "  file_path = os.path.split(zip_file_path)[0]  # get path before /....zip\n",
        "  # unzip training dataset\n",
        "  with zipfile.ZipFile(zip_file_path, 'r') as zipobj:  # open a zip file in read mode\n",
        "    zipobj.extractall(file_path)\n",
        "  #   zip.printdir()    # Display contents of zip file\n",
        "\n",
        "  # walk through the extracted training directory\n",
        "  for root, directories, files in os.walk(file_path): \n",
        "    print(root)\n",
        "    print(directories)\n",
        "    # print(files)\n",
        "\n",
        "\n",
        "local_zip_path = '/tmp/cats_and_dogs_filtered.zip' \n",
        "walk_through_dir(local_zip_path) "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/tmp\n",
            "['cats_and_dogs_filtered']\n",
            "/tmp/cats_and_dogs_filtered\n",
            "['train', 'validation']\n",
            "/tmp/cats_and_dogs_filtered/train\n",
            "['cats', 'dogs']\n",
            "/tmp/cats_and_dogs_filtered/train/cats\n",
            "[]\n",
            "/tmp/cats_and_dogs_filtered/train/dogs\n",
            "[]\n",
            "/tmp/cats_and_dogs_filtered/validation\n",
            "['cats', 'dogs']\n",
            "/tmp/cats_and_dogs_filtered/validation/cats\n",
            "[]\n",
            "/tmp/cats_and_dogs_filtered/validation/dogs\n",
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IheglWMg-GhM",
        "colab_type": "text"
      },
      "source": [
        "## Method 2: Downloading dataset from Internet Link"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1J383w9YwqGo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "8a3df2a0-c5ee-40e2-fa96-9d17dde57a57"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "zip_file = tf.keras.utils.get_file(origin=\"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\",\n",
        "                                   fname=\"/tmp/cats_and_dogs_filtered.zip\", extract=True)\n",
        "base_dir, ext = os.path.splitext(zip_file)\n",
        "print(base_dir,ext)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "68608000/68606236 [==============================] - 1s 0us/step\n",
            "/tmp/cats_and_dogs_filtered .zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdZT0p5MzO_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}